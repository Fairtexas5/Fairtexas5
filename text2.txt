
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Load the data
def load_and_prepare_data(file_path):
    """Load and prepare banking customer data"""
    df = pd.read_csv(file_path)
    
    # Remove empty rows
    df = df.dropna(how='all')
    
    # Convert date columns
    date_columns = ['ACCT_OPN_DT', 'LST_CUST_CR_DT', 'LST_CUST_DR_DT', 'REPORT_DT']
    for col in date_columns:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], format='%d/%m/%y', errors='coerce')
    
    return df

# Feature engineering functions
def create_enhanced_features(df):
    """Create additional features for high-value customer identification"""
    df_enhanced = df.copy()
    
    # 1. Account tenure (existing feature you mentioned)
    if 'ACCT_OPN_DT' in df.columns and 'REPORT_DT' in df.columns:
        df_enhanced['tenure_days'] = (df_enhanced['REPORT_DT'] - df_enhanced['ACCT_OPN_DT']).dt.days
        df_enhanced['tenure_years'] = df_enhanced['tenure_days'] / 365.25
    
    # 2. Transaction behavior features
    df_enhanced['avg_txn_size'] = np.where(
        (df_enhanced['DR_NO'] + df_enhanced['CR_NO']) > 0,
        (df_enhanced['DR_AMT'] + df_enhanced['CR_AMT']) / (df_enhanced['DR_NO'] + df_enhanced['CR_NO']),
        0
    )
    
    df_enhanced['txn_frequency'] = df_enhanced['DR_NO'] + df_enhanced['CR_NO']
    df_enhanced['net_flow'] = df_enhanced['CR_AMT'] - df_enhanced['DR_AMT']
    df_enhanced['txn_volume'] = df_enhanced['DR_AMT'] + df_enhanced['CR_AMT']
    
    # 3. Balance consistency and growth
    df_enhanced['balance_consistency'] = df_enhanced['AVG_BAL_YTD'] / df_enhanced['END_OF_DAY_BAL']
    df_enhanced['balance_growth'] = (df_enhanced['AVG_BAL_YTD'] - df_enhanced['AVG_BAL_MTD']) / df_enhanced['AVG_BAL_MTD']
    
    # 4. Product portfolio metrics
    product_columns = [
        'SAVINGS_BANK', 'FD', 'CA', 'RD', 'OD', 'PERSONAL_LOAN', 'FI_PRODUCT',
        'SME_LOAN', 'GOLD_LOAN', 'AGRI_LOAN', 'EDUCATION_LOAN', 'CAR_LOAN',
        'TWO_WHEELER', 'HOME_LOAN', 'HOME_RELATED', 'AGRI_GOLD_LOAN'
    ]
    
    loan_products = ['PERSONAL_LOAN', 'SME_LOAN', 'GOLD_LOAN', 'AGRI_LOAN', 
                     'EDUCATION_LOAN', 'CAR_LOAN', 'TWO_WHEELER', 'HOME_LOAN']
    
    investment_products = ['FD', 'SAVINGS_BANK', 'RD']
    
    df_enhanced['product_diversity'] = df_enhanced[product_columns].sum(axis=1)
    df_enhanced['loan_products_count'] = df_enhanced[loan_products].sum(axis=1)
    df_enhanced['investment_products_count'] = df_enhanced[investment_products].sum(axis=1)
    
    # 5. Digital engagement score
    digital_channels = ['ATM', 'MBS', 'YONO', 'UPI', 'INB']
    df_enhanced['digital_engagement'] = df_enhanced[digital_channels].sum(axis=1)
    
    # 6. Wealth indicators
    df_enhanced['total_exposure'] = df_enhanced['TDV'] + df_enhanced['HOME_LOAN_AMT']
    df_enhanced['loan_to_deposit_ratio'] = df_enhanced['HOME_LOAN_AMT'] / (df_enhanced['TDV'] + 1)
    
    # 7. Customer tier mapping
    tier_mapping = {
        'PLATINUM': 4, 'GOLD': 3, 'SILVER': 2, 'BRONZE': 1
    }
    df_enhanced['tier_numeric'] = df_enhanced['CUST_CLASS'].map(tier_mapping)
    
    # 8. Risk indicators
    df_enhanced['high_value_txn_ratio'] = np.where(
        df_enhanced['txn_frequency'] > 0,
        (df_enhanced['DR_AMT'] > df_enhanced['DR_AMT'].quantile(0.75)).astype(int),
        0
    )
    
    return df_enhanced

def select_optimal_features(df):
    """Select the most relevant features for high-value customer clustering"""
    
    # Core financial features
    core_features = [
        'END_OF_DAY_BAL',           # Current balance
        'AVG_BAL_YTD',              # Average balance (stability)
        'TDV',                      # Total deposit value
        'AQB',                      # Average quarterly balance
        'HOME_LOAN_AMT',            # Home loan amount
        'total_exposure',           # Total financial exposure
    ]
    
    # Behavioral features
    behavioral_features = [
        'avg_txn_size',             # Transaction size
        'txn_frequency',            # Transaction frequency
        'net_flow',                 # Net money flow
        'tenure_years',             # Customer tenure
        'balance_consistency',      # Balance stability
    ]
    
    # Product engagement features
    product_features = [
        'product_diversity',        # Number of products
        'loan_products_count',      # Loan products
        'investment_products_count', # Investment products
        'digital_engagement',       # Digital channel usage
    ]
    
    # Categorical features (to be encoded)
    categorical_features = [
        'CUST_CAT',                 # Customer category
        'tier_numeric',             # Customer tier
    ]
    
    # Combine all features
    selected_features = core_features + behavioral_features + product_features + categorical_features
    
    return selected_features

def perform_clustering_analysis(df, features, n_clusters=5):
    """Perform customer clustering analysis"""
    
    # Prepare data
    df_cluster = df[features].copy()
    
    # Handle missing values
    df_cluster = df_cluster.fillna(0)
    
    # Handle infinite values
    df_cluster = df_cluster.replace([np.inf, -np.inf], 0)
    
    # Encode categorical variables
    le = LabelEncoder()
    if 'CUST_CAT' in df_cluster.columns:
        df_cluster['CUST_CAT_encoded'] = le.fit_transform(df_cluster['CUST_CAT'].astype(str))
        df_cluster = df_cluster.drop('CUST_CAT', axis=1)
    
    # Scale features
    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(df_cluster)
    
    # Determine optimal number of clusters
    inertias = []
    silhouette_scores = []
    k_range = range(2, 11)
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(df_scaled)
        inertias.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(df_scaled, kmeans.labels_))
    
    # Perform final clustering
    optimal_k = k_range[np.argmax(silhouette_scores)]
    print(f"Optimal number of clusters: {optimal_k}")
    
    kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
    cluster_labels = kmeans_final.fit_predict(df_scaled)
    
    # Add cluster labels to original dataframe
    df_result = df.copy()
    df_result['cluster'] = cluster_labels
    
    return df_result, kmeans_final, scaler, optimal_k, silhouette_scores

def analyze_clusters(df_clustered, features):
    """Analyze and profile each cluster"""
    
    cluster_profiles = {}
    
    for cluster_id in sorted(df_clustered['cluster'].unique()):
        cluster_data = df_clustered[df_clustered['cluster'] == cluster_id]
        
        profile = {
            'size': len(cluster_data),
            'avg_balance': cluster_data['END_OF_DAY_BAL'].mean(),
            'avg_tdv': cluster_data['TDV'].mean(),
            'avg_products': cluster_data['TOTAL_PRODUCT'].mean(),
            'avg_tenure': cluster_data.get('tenure_years', pd.Series([0])).mean(),
            'dominant_tier': cluster_data['CUST_CLASS'].mode().iloc[0] if not cluster_data['CUST_CLASS'].mode().empty else 'Unknown',
            'avg_txn_size': cluster_data.get('avg_txn_size', pd.Series([0])).mean(),
            'digital_engagement': cluster_data.get('digital_engagement', pd.Series([0])).mean(),
        }
        
        cluster_profiles[cluster_id] = profile
    
    return cluster_profiles

def identify_high_value_segments(cluster_profiles):
    """Identify high-value customer segments"""
    
    # Score each cluster based on multiple criteria
    cluster_scores = {}
    
    for cluster_id, profile in cluster_profiles.items():
        # Weighted scoring based on multiple factors
        balance_score = profile['avg_balance'] / 1000000  # Normalize to millions
        tdv_score = profile['avg_tdv'] / 1000000
        product_score = profile['avg_products'] / 10
        tenure_score = profile['avg_tenure'] / 10
        digital_score = profile['digital_engagement'] / 5
        
        # Composite score
        composite_score = (
            balance_score * 0.3 +
            tdv_score * 0.25 +
            product_score * 0.2 +
            tenure_score * 0.15 +
            digital_score * 0.1
        )
        
        cluster_scores[cluster_id] = composite_score
    
    # Rank clusters by score
    ranked_clusters = sorted(cluster_scores.items(), key=lambda x: x[1], reverse=True)
    
    return ranked_clusters, cluster_scores

# Main execution function
def main():
    # Load data (you'll need to provide the actual file path)
    print("Loading and preparing data...")
    # df = load_and_prepare_data('Book1_small.csv')
    
    # For demonstration, create sample data structure
    print("Creating enhanced features...")
    # df_enhanced = create_enhanced_features(df)
    
    print("Selecting optimal features...")
    # selected_features = select_optimal_features(df_enhanced)
    
    print("Recommended features for high-value customer clustering:")
    recommended_features = [
        # Core Financial Metrics
        'END_OF_DAY_BAL',           # Current account balance
        'AVG_BAL_YTD',              # Year-to-date average balance
        'TDV',                      # Total deposit value
        'AQB',                      # Average quarterly balance
        'HOME_LOAN_AMT',            # Home loan amount
        
        # Transaction Behavior
        'avg_txn_size',             # Average transaction size
        'txn_frequency',            # Number of transactions
        'net_flow',                 # Net money flow (CR_AMT - DR_AMT)
        'txn_volume',               # Total transaction volume
        
        # Product Portfolio
        'TOTAL_PRODUCT',            # Total number of products
        'product_diversity',        # Diversity of product portfolio
        'loan_products_count',      # Number of loan products
        'investment_products_count', # Number of investment products
        
        # Digital Engagement
        'digital_engagement',       # Digital channel usage score
        'ATM', 'MBS', 'YONO', 'UPI', 'INB',  # Individual digital channels
        
        # Customer Longevity & Stability
        'tenure_years',             # Customer tenure in years
        'balance_consistency',      # Balance stability ratio
        
        # Customer Tier & Category
        'tier_numeric',             # Numeric tier (Platinum=4, Gold=3, etc.)
        'CUST_CAT',                 # Customer category
        
        # Risk & Relationship Indicators
        'total_exposure',           # Total financial exposure
        'loan_to_deposit_ratio',    # Loan to deposit ratio
    ]
    
    print("\nRecommended Feature Categories:")
    print("=" * 50)
    print("1. CORE FINANCIAL METRICS:")
    print("   - END_OF_DAY_BAL, AVG_BAL_YTD, TDV, AQB, HOME_LOAN_AMT")
    print("\n2. BEHAVIORAL METRICS:")
    print("   - avg_txn_size, txn_frequency, net_flow, balance_consistency")
    print("\n3. PRODUCT ENGAGEMENT:")
    print("   - TOTAL_PRODUCT, product_diversity, loan_products_count")
    print("\n4. DIGITAL ADOPTION:")
    print("   - digital_engagement, ATM, YONO, UPI, INB")
    print("\n5. CUSTOMER PROFILE:")
    print("   - tenure_years, tier_numeric, CUST_CAT")
    
    print("\n" + "=" * 50)
    print("CLUSTERING METHODOLOGY:")
    print("=" * 50)
    print("1. Feature Engineering: Create derived metrics")
    print("2. Feature Selection: Use correlation analysis & domain knowledge")
    print("3. Preprocessing: Scale features & handle missing values")
    print("4. Clustering: Use K-means with optimal k selection")
    print("5. Validation: Silhouette analysis & business logic")
    print("6. Profiling: Analyze cluster characteristics")
    print("7. High-Value Identification: Score clusters on multiple criteria")

if __name__ == "__main__":
    main()

# Additional utility functions for your analysis

def create_clustering_pipeline(df, selected_features):
    """Complete clustering pipeline"""
    
    # Create enhanced features
    df_enhanced = create_enhanced_features(df)
    
    # Perform clustering
    df_clustered, model, scaler, optimal_k, scores = perform_clustering_analysis(
        df_enhanced, selected_features
    )
    
    # Analyze clusters
    profiles = analyze_clusters(df_clustered, selected_features)
    
    # Identify high-value segments
    ranked_clusters, cluster_scores = identify_high_value_segments(profiles)
    
    return {
        'clustered_data': df_clustered,
        'model': model,
        'scaler': scaler,
        'profiles': profiles,
        'ranked_clusters': ranked_clusters,
        'cluster_scores': cluster_scores
    }

# Example usage:
"""
# Load your data
df = pd.read_csv('Book1_small.csv')

# Define features
features = [
    'END_OF_DAY_BAL', 'AVG_BAL_YTD', 'TDV', 'AQB', 'HOME_LOAN_AMT',
    'TOTAL_PRODUCT', 'SAVINGS_BANK', 'FD', 'HOME_LOAN', 'PERSONAL_LOAN',
    'ATM', 'YONO', 'UPI', 'INB', 'CUST_CAT', 'CUST_CLASS'
]

# Run clustering pipeline
results = create_clustering_pipeline(df, features)

# Get high-value customers
high_value_cluster = results['ranked_clusters'][0][0]  # Top cluster
high_value_customers = results['clustered_data'][
    results['clustered_data']['cluster'] == high_value_cluster
]
"""
