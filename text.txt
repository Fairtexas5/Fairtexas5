import pandas as pd
import numpy as np
from sklearn.metrics import silhouette_score
import hdbscan
import warnings
warnings.filterwarnings('ignore', category=UserWarning)

# Step 1: Load Embedding
print("Step 1: Loading TruncatedSVD embedding...")
try:
    embedding = pd.read_pickle('svd_embedding_with_categorical.pkl')
    print(f"Loaded embedding from 'svd_embedding_with_categorical.pkl': Shape = {embedding.shape}")
except FileNotFoundError:
    if 'SVD1' in df_customer.columns and 'SVD2' in df_customer.columns:
        embedding = df_customer[['SVD1', 'SVD2']].astype('float32')
        print(f"Using SVD1 and SVD2 from df_customer: Shape = {embedding.shape}")
    else:
        raise ValueError("Embedding not found. Ensure 'svd_embedding_with_categorical.pkl' or 'SVD1', 'SVD2' in df_customer.")

# Step 2: HDBSCAN Clustering
print("Step 2: Running HDBSCAN clustering...")
clusterer = hdbscan.HDBSCAN(
    min_cluster_size=500,      # Minimum customers per segment
    min_samples=10,            # Noise threshold
    cluster_selection_method='eom',  # Excess of Mass for robust clusters
    n_jobs=-1,                 # Use all 5 vCPUs
)
labels = clusterer.fit_predict(embedding)
df_customer['Cluster'] = labels
print(f"Clustering complete: {len(np.unique(labels))} clusters (including noise label -1)")
print(f"Number of noise points: {(labels == -1).sum()}")

# Step 3: Evaluation - Silhouette Score
print("Step 3: Evaluating cluster quality...")
sample_idx = np.random.choice(len(embedding), 10000, replace=False)
silhouette = silhouette_score(embedding.iloc[sample_idx], labels[sample_idx])
print(f"Silhouette Score (sample of 10,000): {silhouette:.4f}")

# Step 4: Cluster Summary for High-Value Segmentation
print("Step 4: Summarizing clusters...")
cluster_summary = df_customer.groupby('Cluster').agg({
    'AVG_BAL_QTD': 'mean',       # Average quarterly balance
    'TXN_FREQ': 'mean',          # Transaction frequency
    'DIGITAL_ENGAGE': 'mean',    # Digital engagement
    'TOTAL_PRODUCT': 'mean',     # Total products
    'HIGHEST_TIER': lambda x: x.mode().iloc[0] if x.mode().size > 0 else 'Unknown',  # Most common tier
    'CUST_NBR': 'count'          # Number of customers
}).rename(columns={'CUST_NBR': 'Customer_Count'}).reset_index()
print("\nCluster Summary:")
print(cluster_summary)

# Identify high-value clusters
high_value_clusters = cluster_summary[
    (cluster_summary['AVG_BAL_QTD'] > cluster_summary['AVG_BAL_QTD'].median()) &
    (cluster_summary['TXN_FREQ'] > cluster_summary['TXN_FREQ'].median()) &
    (cluster_summary['DIGITAL_ENGAGE'] > cluster_summary['DIGITAL_ENGAGE'].median())
]['Cluster'].tolist()
print(f"\nHigh-Value Clusters: {high_value_clusters}")

# Step 5: Save Results
df_customer.to_pickle('clustered_data.pkl')
print("Clustered data saved to 'clustered_data.pkl'")
cluster_summary.to_csv('cluster_summary.csv', index=False)
print("Cluster summary saved to 'cluster_summary.csv'")

# Optional: Visualize Clusters
try:
    import matplotlib.pyplot as plt
    plt.figure(figsize=(10, 6))
    scatter = plt.scatter(
        embedding['SVD1'], embedding['SVD2'], 
        c=labels, cmap='Spectral', s=1, alpha=0.5
    )
    plt.colorbar(scatter, label='Cluster')
    plt.title('HDBSCAN Clusters on TruncatedSVD Embedding')
    plt.xlabel('SVD1')
    plt.ylabel('SVD2')
    plt.savefig('hdbscan_clustering.png')
    plt.close()
    print("Cluster visualization saved to 'hdbscan_clustering.png'")
except ImportError:
    print("Matplotlib not installed. Skipping visualization.")
