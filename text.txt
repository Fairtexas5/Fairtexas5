import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.decomposition import KernelPCA
from sklearn.compose import ColumnTransformer
import warnings
warnings.filterwarnings('ignore', category=UserWarning)  # Suppress warnings

# Step 1: Data Preparation
print("Step 1: Preparing data for Kernel PCA...")

# Select numeric and categorical columns
numeric_cols = df_customer.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = ['CUST_CLASS', 'CUST_CAT', 'JNT_ACCT_FLG', 'HIGHEST_TIER', 'MRTL_STS']
ordinal_cols = ['ACT_LVL']
all_cols = list(numeric_cols) + categorical_cols + ordinal_cols
print(f"Selected {len(numeric_cols)} numeric features: {list(numeric_cols)}")
print(f"Selected {len(categorical_cols)} categorical features: {categorical_cols}")
print(f"Selected {len(ordinal_cols)} ordinal feature: {ordinal_cols}")

# Define preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_cols),
        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_cols),
        ('ord', OrdinalEncoder(categories=[['Low', 'Medium', 'High', 'Very_High']]), ordinal_cols)
    ],
    remainder='drop'  # Drop CUST_NBR, date columns
)

# Apply preprocessing
df_processed = preprocessor.fit_transform(df_customer[all_cols])
# Get feature names for one-hot encoded columns
cat_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)
feature_names = list(numeric_cols) + list(cat_feature_names) + ordinal_cols
df_processed = pd.DataFrame(df_processed, columns=feature_names, index=df_customer.index).astype('float32')
print(f"Preprocessed data shape: {df_processed.shape} (includes {len(cat_feature_names)} one-hot encoded features)")

# Step 2: Dimensionality Reduction with Kernel PCA
print("Step 2: Running Kernel PCA dimensionality reduction...")
kpca = KernelPCA(
    n_components=2,      # Reduce to 2D
    kernel='rbf',        # Non-linear RBF kernel
    gamma=None,          # Auto: 1/n_features
    n_jobs=-1,           # Use all 5 vCPUs
    random_state=42      # Reproducibility
)
embedding = kpca.fit_transform(df_processed)
embedding = pd.DataFrame(embedding, columns=['KPCA1', 'KPCA2'], index=df_customer.index).astype('float32')
print(f"Kernel PCA reduction complete: Shape of embedding = {embedding.shape}")

# Step 3: Add embedding to original DataFrame
df_customer['KPCA1'] = embedding['KPCA1']
df_customer['KPCA2'] = embedding['KPCA2']
print(f"Added KPCA1 and KPCA2 to df_customer. New shape: {df_customer.shape}")

# Step 4: Save embedding for clustering
embedding.to_pickle('kpca_embedding.pkl')
print("Kernel PCA embedding saved to 'kpca_embedding.pkl'")

# Optional: Visualize
try:
    import matplotlib.pyplot as plt
    plt.figure(figsize=(10, 6))
    plt.scatter(embedding['KPCA1'], embedding['KPCA2'], s=1, alpha=0.5)
    plt.title('Kernel PCA Embedding of Customers')
    plt.xlabel('KPCA1')
    plt.ylabel('KPCA2')
    plt.savefig('kpca_visualization.png')
    plt.close()
    print("Kernel PCA visualization saved to 'kpca_visualization.png'")
except ImportError:
    print("Matplotlib not installed. Skipping visualization.")
